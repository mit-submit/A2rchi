name: {{ name | default("default", true) }}

global:
  TRAINED_ON: {{ global.TRAINED_ON | default("", true) }}
  DATA_PATH: "{{ global.DATA_PATH | default('/root/data/', true) }}"
  ACCOUNTS_PATH: "{{ global.ACCOUNTS_PATH | default('/root/.accounts/', true) }}"
  LOCAL_VSTORE_PATH: "{{ global.LOCAL_VSTORE_PATH | default('/root/data/vstore/', true) }}"
  ACCEPTED_FILES: 
    {%- for file_type in global.ACCEPTED_FILES | default(['.txt', '.html', '.pdf']) %}
    - "{{ file_type }}"
    {%- endfor %}

interfaces:
  {%- if interfaces and 'chat_app' in interfaces %}
  chat_app:
    PORT: {{ interfaces.chat_app.PORT | default(7861, true) }}
    EXTERNAL_PORT: {{ interfaces.chat_app.EXTERNAL_PORT | default(7861, true) }}
    HOST: {{ interfaces.chat_app.HOST | default("0.0.0.0", true) }}
    HOSTNAME: {{ interfaces.chat_app.HOSTNAME | default("localhost", true) }}
    template_folder: "{{ interfaces.chat_app.template_folder | default('/root/A2rchi/a2rchi/interfaces/chat_app/templates', true) }}"
    static_folder: "{{ interfaces.chat_app.static_folder | default('/root/A2rchi/a2rchi/interfaces/chat_app/static', true) }}"
    num_responses_until_feedback: {{ interfaces.chat_app.num_responses_until_feedback | default(3, true) }}
    include_copy_button: {{ interfaces.chat_app.include_copy_button | default(false, true) }}
    enable_debug_chroma_endpoints: {{ interfaces.chat_app.enable_debug_chroma_endpoints | default(false, true) }}
    flask_debug_mode: {{ interfaces.chat_app.flask_debug_mode | default(true, false) }}
  {%- endif %}
  {%- if interfaces and 'uploader_app' in interfaces %}
  uploader_app:
    PORT: {{ interfaces.uploader_app.PORT | default(5001, true) }}
    EXTERNAL_PORT: {{ interfaces.uploader_app.EXTERNAL_PORT | default(5003, true) }}
    HOST: {{ interfaces.uploader_app.HOST | default("0.0.0.0", true) }} # either "0.0.0.0" (for public) or "127.0.0.1" (for internal)
    template_folder: {{ interfaces.uploader_app.template_folder | default("/root/A2rchi/a2rchi/interfaces/uploader_app/templates", true) }}
    verify_urls: {{interfaces.uploader_app.verify_urls | default(true, false) }}
    flask_debug_mode: {{ interfaces.uploader_app.flask_debug_mode | default(true, false) }}
  {%- endif %}
  {%- if interfaces and 'grader_app' in interfaces %}
  grader_app:
    PORT: {{ interfaces.grader_app.PORT | default(7861, true) }}
    EXTERNAL_PORT: {{ interfaces.grader_app.EXTERNAL_PORT | default(7861, true) }}
    HOST: {{ interfaces.grader_app.HOST | default("0.0.0.0", true) }}
    HOSTNAME: {{ interfaces.grader_app.HOSTNAME | default("localhost", true) }}
    template_folder: {{ interfaces.grader_app.template_folder | default("/root/A2rchi/a2rchi/interfaces/grader_app/templates", true) }}
    num_problems: {{ interfaces.grader_app.num_problems | default(1, true) }}
    local_rubric_dir: {{ interfaces.grader_app.rubric_dir }}
    local_users_csv_dir: {{ interfaces.grader_app.local_users_csv }}
    flask_debug_mode: {{ interfaces.grader_app.flask_debug_mode | default(true, false) }}
  {%- endif %}
  {%- if interfaces and 'grafana' in interfaces %}
  grafana:
    EXTERNAL_PORT: {{ interfaces.grafana.EXTERNAL_PORT | default(3000, true) }}
  {%- endif %}

chains:
  input_lists:
    {%- for input_list in chains.input_lists | default([]) %}
    - {{ input_list }}
    {%- endfor %}
  base:
    ROLES:
      {%- for role in chains.base.ROLES | default(['User', 'A2rchi', 'Expert']) %}
      - {{ role }}
      {%- endfor %}
    logging:
      input_output_filename: "{{ chains.base.logging.input_output_filename | default('chain_input_output.log', true) }}"
  prompts:
    CONDENSING_PROMPT: "{{ '/root/A2rchi/condense.prompt' if chains.chain.CONDENSE_MODEL_NAME else null }}"
    MAIN_PROMPT: "{{ '/root/A2rchi/main.prompt' if chains.chain.MODEL_NAME else null }}"
    IMAGE_PROCESSING_PROMPT: "{{ '/root/A2rchi/image_processing.prompt' if chains.chain.IMAGE_PROCESSING_MODEL_NAME else null }}"
    GRADING_SUMMARY_PROMPT: "{{ '/root/A2rchi/grading_summary.prompt' if chains.chain.GRADING_SUMMARY_MODEL_NAME else null }}"
    GRADING_ANALYSIS_PROMPT: "{{ '/root/A2rchi/grading_analysis.prompt' if chains.chain.GRADING_ANALYSIS_MODEL_NAME else null }}"
    GRADING_FINAL_GRADE_PROMPT: "{{ '/root/A2rchi/grading_final_grade.prompt' if chains.chain.GRADING_FINAL_GRADE_MODEL_NAME else null }}"
  chain:
    MODEL_NAME: {{ chains.chain.MODEL_NAME | default('null', true) }}
    CONDENSE_MODEL_NAME: {{ chains.chain.CONDENSE_MODEL_NAME | default('null', true) }}
    CLEO_MODEL_NAME: {{ chains.chain.CLEO_MODEL_NAME | default('null', true) }}
    IMAGE_PROCESSING_MODEL_NAME: {{ chains.chain.IMAGE_PROCESSING_MODEL_NAME | default('null', true) }}
    GRADING_SUMMARY_MODEL_NAME: {{ chains.chain.GRADING_SUMMARY_MODEL_NAME | default('null', true) }}
    GRADING_ANALYSIS_MODEL_NAME: {{ chains.chain.GRADING_ANALYSIS_MODEL_NAME | default('null', true) }}
    GRADING_FINAL_GRADE_MODEL_NAME: {{ chains.chain.GRADING_FINAL_GRADE_MODEL_NAME | default('null', true) }}
    MAX_MODEL_TOKENS: {{ chains.chain.MAX_MODEL_TOKENS | default(10000, true) }}
    MODEL_CLASS_MAP:
      {%- if chains and chains.chain and chains.chain.MODEL_CLASS_MAP and 'AnthropicLLM' in chains.chain.MODEL_CLASS_MAP %}
      AnthropicLLM:
        class: AnthropicLLM
        kwargs:
          model_name: {{ chains.chain.MODEL_CLASS_MAP.AnthropicLLM.kwargs.model_name | default('claude-3-opus-20240229', true) }}
          temperature: {{ chains.chain.MODEL_CLASS_MAP.AnthropicLLM.kwargs.temperature | default(1, true) }}
      {%- endif %}
      {%- if chains and chains.chain and chains.chain.MODEL_CLASS_MAP and 'OpenAIGPT4' in chains.chain.MODEL_CLASS_MAP %}
      OpenAIGPT4:
        class: OpenAILLM
        kwargs:
          model_name: {{ chains.chain.MODEL_CLASS_MAP.OpenAIGPT4.kwargs.model_name | default('gpt-4', true) }}
          temperature: {{ chains.chain.MODEL_CLASS_MAP.OpenAIGPT4.kwargs.temperature | default(1, true) }}
      {%- endif %}
      {%- if chains and chains.chain and chains.chain.MODEL_CLASS_MAP and 'OpenAIGPT35' in chains.chain.MODEL_CLASS_MAP %}
      OpenAIGPT35:
        class: OpenAILLM
        kwargs:
          model_name: {{ chains.chain.MODEL_CLASS_MAP.OpenAIGPT35.kwargs.model_name | default('gpt-3.5-turbo', true) }}
          temperature: {{ chains.chain.MODEL_CLASS_MAP.OpenAIGPT35.kwargs.temperature | default(1, true) }}
      {%- endif %}
      {%- if chains and chains.chain and chains.chain.MODEL_CLASS_MAP and 'DumbLLM' in chains.chain.MODEL_CLASS_MAP %}
      DumbLLM:
        class: DumbLLM
        kwargs:
          sleep_time_mean: {{ chains.chain.MODEL_CLASS_MAP.DumbLLM.kwargs.sleep_time_mean | default(3, true) }}
          filler: {{ chains.chain.MODEL_CLASS_MAP.DumbLLM.kwargs.filler | default('null', true) }}
      {%- endif %}
      {%- if chains and chains.chain and chains.chain.MODEL_CLASS_MAP and 'LlamaLLM' in chains.chain.MODEL_CLASS_MAP %}
      LlamaLLM:
        class: LlamaLLM
        kwargs:
          base_model: {{ chains.chain.MODEL_CLASS_MAP.LlamaLLM.kwargs.base_model | default("meta-llama/Llama-2-7b-chat-hf", true) }}
          peft_model: {{ chains.chain.MODEL_CLASS_MAP.LlamaLLM.kwargs.peft_model | default("null", true) }}
          enable_salesforce_content_safety: {{ chains.chain.MODEL_CLASS_MAP.LlamaLLM.kwargs.enable_salesforce_content_safety | default(false, false) }}
          quantization: {{ chains.chain.MODEL_CLASS_MAP.LlamaLLM.kwargs.quantization | default(true, true) }}
          max_new_tokens: {{ chains.chain.MODEL_CLASS_MAP.LlamaLLM.kwargs.max_new_tokens | default(4096, true) }}
          seed: {{ chains.chain.MODEL_CLASS_MAP.LlamaLLM.kwargs.seed | default("null", true) }}
          do_sample: {{ chains.chain.MODEL_CLASS_MAP.LlamaLLM.kwargs.do_sample | default(true, true) }}
          min_length: {{ chains.chain.MODEL_CLASS_MAP.LlamaLLM.kwargs.min_length | default("null", true) }}
          use_cache: {{ chains.chain.MODEL_CLASS_MAP.LlamaLLM.kwargs.use_cache | default(true, true) }}
          top_p: {{ chains.chain.MODEL_CLASS_MAP.LlamaLLM.kwargs.top_p | default(0.9, true) }}
          temperature: {{ chains.chain.MODEL_CLASS_MAP.LlamaLLM.kwargs.temperature | default(0.6, true) }}
          top_k: {{ chains.chain.MODEL_CLASS_MAP.LlamaLLM.kwargs.top_k | default(50, true) }}
          repetition_penalty: {{ chains.chain.MODEL_CLASS_MAP.LlamaLLM.kwargs.repetition_penalty | default(1.0, true) }}
          length_penalty: {{ chains.chain.MODEL_CLASS_MAP.LlamaLLM.kwargs.length_penalty | default(1, true) }}
          max_padding_length: {{ chains.chain.MODEL_CLASS_MAP.LlamaLLM.kwargs.max_padding_length | default("null", true) }}
      {%- endif %}
      {%- if chains and chains.chain and chains.chain.MODEL_CLASS_MAP and 'HuggingFaceOpenLLM' in chains.chain.MODEL_CLASS_MAP %}
      HuggingFaceOpenLLM:
        class: HuggingFaceOpenLLM
        kwargs:
          base_model: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceOpenLLM.kwargs.base_model | default("Qwen/Qwen2.5-7B-Instruct-1M", true) }}
          peft_model: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceOpenLLM.kwargs.peft_model | default("null", true) }}
          enable_salesforce_content_safety: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceOpenLLM.kwargs.enable_salesforce_content_safety | default(false, false) }}
          quantization: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceOpenLLM.kwargs.quantization | default(true, true) }}
          max_new_tokens: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceOpenLLM.kwargs.max_new_tokens | default(4096, true) }}
          seed: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceOpenLLM.kwargs.seed | default("null", true) }}
          do_sample: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceOpenLLM.kwargs.do_sample | default(true, true) }}
          min_length: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceOpenLLM.kwargs.min_length | default("null", true) }}
          use_cache: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceOpenLLM.kwargs.use_cache | default(true, true) }}
          top_p: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceOpenLLM.kwargs.top_p | default(0.9, true) }}
          temperature: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceOpenLLM.kwargs.temperature | default(0.6, true) }}
          top_k: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceOpenLLM.kwargs.top_k | default(50, true) }}
          repetition_penalty: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceOpenLLM.kwargs.repetition_penalty | default(1.0, true) }}
          length_penalty: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceOpenLLM.kwargs.length_penalty | default(1, true) }}
          max_padding_length: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceOpenLLM.kwargs.max_padding_length | default("null", true) }}
      {%- endif %}
      {%- if chains and chains.chain and chains.chain.MODEL_CLASS_MAP and 'HuggingFaceImageLLM' in chains.chain.MODEL_CLASS_MAP %}
      HuggingFaceImageLLM:
        class: HuggingFaceImageLLM
        kwargs:
          base_model: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceImageLLM.kwargs.base_model | default("Qwen/Qwen2.5-VL-7B-Instruct", true) }}
          quantization: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceImageLLM.kwargs.quantization | default(true, true) }}
          min_pixels: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceImageLLM.kwargs.min_pixels | default(175616, true) }}
          max_pixels: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceImageLLM.kwargs.max_pixels | default(1003520, true) }}
          max_new_tokens: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceImageLLM.kwargs.max_new_tokens | default(4096, true) }}
          seed: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceImageLLM.kwargs.seed | default("null", true) }}
          do_sample: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceImageLLM.kwargs.do_sample | default(false, false) }}
          min_length: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceImageLLM.kwargs.min_length | default("null", true) }}
          use_cache: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceImageLLM.kwargs.use_cache | default(true, true) }}
          top_k: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceImageLLM.kwargs.top_k | default(50, true) }}
          repetition_penalty: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceImageLLM.kwargs.repetition_penalty | default(1.0, true) }}
          length_penalty: {{ chains.chain.MODEL_CLASS_MAP.HuggingFaceImageLLM.kwargs.length_penalty | default(1, true) }}
      {%- endif %}
      {%- if chains and chains.chain and chains.chain.MODEL_CLASS_MAP and 'VLLM' in chains.chain.MODEL_CLASS_MAP %}
      VLLM:
        class: VLLM
        kwargs:
          base_model: {{ chains.chain.MODEL_CLASS_MAP.VLLM.kwargs.base_model | default("deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B", true) }}
          seed: {{ chains.chain.MODEL_CLASS_MAP.VLLM.kwargs.seed | default("null", true) }}
          enable_salesforce_content_safety: {{ chains.chain.MODEL_CLASS_MAP.VLLM.kwargs.enable_salesforce_content_safety | default(false, false) }}
          max_new_tokens: {{ chains.chain.MODEL_CLASS_MAP.VLLM.kwargs.max_new_tokens | default(4096, true) }}
          top_p: {{ chains.chain.MODEL_CLASS_MAP.VLLM.kwargs.top_p | default(0.95, true) }}
          temperature: {{ chains.chain.MODEL_CLASS_MAP.VLLM.kwargs.temperature | default(0.6, true) }}
          top_k: {{ chains.chain.MODEL_CLASS_MAP.VLLM.kwargs.top_k | default(50, true) }}
          repetition_penalty: {{ chains.chain.MODEL_CLASS_MAP.VLLM.kwargs.repetition_penalty | default(1.0, true) }}
          tensor_parallel_size: {{ chains.chain.MODEL_CLASS_MAP.VLLM.kwargs.tensor_parallel_size | default(1, true) }}
          gpu_memory_utilization: {{ chains.chain.MODEL_CLASS_MAP.VLLM.kwargs.gpu_memory_utilization | default(0.7, true) }}
          trust_remote_code: {{ chains.chain.MODEL_CLASS_MAP.VLLM.kwargs.trust_remote_code | default(true, true) }}
          tokenizer_mode: {{ chains.chain.MODEL_CLASS_MAP.VLLM.kwargs.tokenizer_mode | default("auto", true) }}
          max_model_len: {{ chains.chain.MODEL_CLASS_MAP.VLLM.kwargs.max_model_len | default(none, true) }}
        {%- if chains and chains.chain and chains.chain.MODEL_CLASS_MAP and chains.chain.MODEL_CLASS_MAP.VLLM and 'env' in chains.chain.MODEL_CLASS_MAP.VLLM %}
        env:
          {%- for key, value in chains.chain.MODEL_CLASS_MAP.VLLM.env.items() %}
          {{ key }}: "{{ value }}"
          {%- endfor %}
        {%- endif %}
      {%- endif %}
      {%- if chains and chains.chain and chains.chain.MODEL_CLASS_MAP and 'OllamaInterface' in chains.chain.MODEL_CLASS_MAP %}
      OllamaInterface:
        class: OllamaInterface
        kwargs: 
          base_model: {{ chains.chain.MODEL_CLASS_MAP.OllamaInterface.kwargs.base_model | default("null", true) }}
          url: {{ chains.chain.MODEL_CLASS_MAP.OllamaInterface.kwargs.url | default("null", true) }}
          num_ctx: {{ chains.chain.MODEL_CLASS_MAP.OllamaInterface.kwargs.num_ctx | default(2048, true) }} # context window size
          num_predict: {{ chains.chain.MODEL_CLASS_MAP.OllamaInterface.kwargs.num_predict | default(4096, true) }} # max tokens to predict
          temperature: {{ chains.chain.MODEL_CLASS_MAP.OllamaInterface.kwargs.temperature | default(0.6, true) }}
          top_p: {{ chains.chain.MODEL_CLASS_MAP.OllamaInterface.kwargs.top_p | default(0.95, true) }}
          top_k: {{ chains.chain.MODEL_CLASS_MAP.OllamaInterface.kwargs.top_k | default(50, true) }}
          num_gpu: {{ chains.chain.MODEL_CLASS_MAP.OllamaInterface.kwargs.num_gpu | default(-1, true) }} # may want to make this autodetectable somehow
          repeat_penalty: {{ chains.chain.MODEL_CLASS_MAP.OllamaInterface.kwargs.repeat_penalty | default(1.0, true) }} 
      {%- endif %} 
    chain_update_time: {{ chains.chain.chain_update_time | default(10, true) }}

utils:
  {%- if utils and 'postgres' in utils %}
  postgres:
    port: {{ utils.postgres.port | default(5432, true) }}
    user: {{ utils.postgres.user | default('a2rchi', true) }}
    database: {{ utils.postgres.database | default('a2rchi-db', true) }}
    host: {{ postgres_hostname }}
  {%- endif %}
  {%- if utils and 'data_manager' in utils %}
  data_manager:
    stemming:
      ENABLED: {{ utils.data_manager.stemming.ENABLED | default(false, true) }}
    CHUNK_SIZE: {{ utils.data_manager.CHUNK_SIZE | default(1000, true) }}
    CHUNK_OVERLAP: {{ utils.data_manager.CHUNK_OVERLAP | default(0, true) }}
    use_HTTP_chromadb_client: {{ utils.data_manager.use_HTTP_chromadb_client | default(true, true) }}
    chromadb_host: {{ utils.data_manager.chromadb_host | default('chromadb', true) }} # This should not be changed, it corresponds to the service name, 'chromadb', specified in the compose.yaml
    chromadb_port: {{ utils.data_manager.chromadb_port | default(8000, true) }} # This should never really need to be changed off of 8000
    chromadb_external_port:  {{ utils.data_manager.chromadb_external_port | default(8000, true) }}
    collection_name: {{ collection_name }}
    reset_collection: {{ utils.data_manager.reset_collection | default(true, true) }}
    num_documents_to_retrieve: {{ utils.data_manager.num_documents_to_retrieve | default(5, true) }}
    distance_metric: {{ utils.data_manager.distance_metric | default('cosine', true) }}
    use_hybrid_search: {{ utils.data_manager.use_hybrid_search | default(false, true) }}
    bm25_weight: {{ utils.data_manager.bm25_weight | default(0.6, true) }}
    semantic_weight: {{ utils.data_manager.semantic_weight | default(0.4, true) }}
    bm25:
      k1: {{ utils.data_manager.bm25.k1 | default(0.5, true) }}
      b: {{ utils.data_manager.bm25.b | default(0.75, true) }}
  {%- endif %}
  {%- if utils and 'embeddings' in utils %}
  embeddings:
    EMBEDDING_NAME: {{ utils.embeddings.EMBEDDING_NAME | default('OpenAIEmbeddings', true) }}
    EMBEDDING_CLASS_MAP:
      {%- if utils and utils.embeddings and utils.embeddings.EMBEDDING_CLASS_MAP and 'OpenAIEmbeddings' in utils.embeddings.EMBEDDING_CLASS_MAP %}
      OpenAIEmbeddings:
        class: OpenAIEmbeddings
        kwargs:
          model: {{ utils.embeddings.EMBEDDING_CLASS_MAP.OpenAIEmbeddings.kwargs.model | default('text-embedding-3-small', true) }}
        similarity_score_reference: {{ utils.embeddings.EMBEDDING_CLASS_MAP.OpenAIEmbeddings.similarity_score_reference | default(10, true) }}
      {%- endif %}
      {%- if utils and utils.embeddings and utils.embeddings.EMBEDDING_CLASS_MAP and 'HuggingFaceEmbeddings' in utils.embeddings.EMBEDDING_CLASS_MAP %}
      HuggingFaceEmbeddings:
        class: HuggingFaceEmbeddings
        kwargs:
          model_name: {{ utils.embeddings.EMBEDDING_CLASS_MAP.HuggingFaceEmbeddings.kwargs.model_name | default('sentence-transformers/all-MiniLM-L6-v2', true) }}
          model_kwargs:
            device: {{ utils.embeddings.EMBEDDING_CLASS_MAP.HuggingFaceEmbeddings.kwargs.model_kwargs.device | default('cpu', true) }}
          encode_kwargs: 
            normalize_embeddings: {{ utils.embeddings.EMBEDDING_CLASS_MAP.HuggingFaceEmbeddings.kwargs.encode_kwargs.normalize_embeddings | default(true, true) }}
        similarity_score_reference: {{ utils.embeddings.EMBEDDING_CLASS_MAP.HuggingFaceEmbeddings.similarity_score_reference | default(10, true) }}
      {%- endif %}
    query_embedding_instructions: {{ utils.embeddings.query_embedding_instructions | default("null", true) }}
  {%- endif %}
  {%- if utils and 'sso' in utils %}
  sso:
    ENABLED: {{ utils.sso.ENABLED | default(false, true) }}
    SSO_CLASS: {{ utils.sso.SSO_CLASS | default('CERNSSOScraper', true) }}
    SSO_CLASS_MAP:
      CERNSSOScraper:
        class: CERNSSOScraper
        kwargs:
          headless: {{ utils.sso.SSO_CLASS_MAP.CERNSSOScraper.kwargs.headless | default(true, true) }}
          max_depth: {{ utils.sso.SSO_CLASS_MAP.CERNSSOScraper.kwargs.max_depth | default(2, true) }}
  {%- endif %}
  {%- if utils and 'git' in utils %}
  git:
    ENABLED: {{ utils.git.ENABLED | default(false, true) }}
  {%- endif %}
  {%- if utils and 'scraper' in utils %}
  scraper:
    reset_data: {{ utils.scraper.reset_data | default(true, true) }}
    verify_urls: {{ utils.scraper.verify_urls | default(false, true) }}
    enable_warnings: {{ utils.scraper.enable_warnings | default(false, true) }}
  {%- endif %}
  {%- if utils and 'piazza' in utils %}
  piazza:
    network_id: {{ utils.piazza.network_id }}
    update_time: {{ utils.piazza.update_time | default(60, true) }} # seconds
  {%- endif %}
  {%- if utils and 'mattermost' in utils %}
  mattermost:
    update_time: {{ utils.mattermost.update_time | default(60, true) }} # seconds
  {%- endif %}
  {%- if utils and 'redmine' in utils %}
  redmine:
    redmine_update_time: {{ utils.redmine.redmine_update_time | default(10, true) }}
    answer_tag: {{ utils.redmine.answer_tag | default('-- A2rchi -- Resolving email was sent', true)}}
    redmine_update_time: {{ utils.redmine.redmine_update_time | default(10, true) }}
  {%- endif %}
  {%- if utils and 'mailbox' in utils %}
  mailbox: 
    IMAP4_PORT:  {{ utils.mailbox.IMAP4_PORT | default(143, true) }}
    mailbox_update_time: {{ utils.mailbox.mailbox_update_time | default(10, true) }}
  {%- endif %}
  {%- if utils and 'jira' in utils %}
  jira:
    JIRA_URL: {{ utils.jira.JIRA_URL }}
    JIRA_PROJECTS: 
      {%- for project in utils.jira.JIRA_PROJECTS %}
      - {{ project }}
      {%- endfor %}
    ANONYMIZE_DATA: {{ utils.jira.ANONYMIZE_DATA | default(true, true) }}
  {%- endif %}
  {%- if utils and 'anonymizer' in utils %}
  anonymizer:
    nlp_model: {{ utils.anonymizer.nlp_model | default('en_core_web_sm', true) }}
    excluded_words: 
      {%- for word in utils.anonymizer.excluded_words | default(['John', 'Jane', 'Doe']) %}
      - {{ word }}
      {%- endfor %}
    greeting_patterns: 
      {%- for pattern in utils.anonymizer.greeting_patterns | default(['^(hi|hello|hey|greetings|dear)\\b', '^\\w+,\\s*']) %}
      - {{ pattern }}
      {%- endfor %}
    signoff_patterns: 
      {%- for pattern in utils.anonymizer.signoff_patterns | default(['\\b(regards|sincerely|best regards|cheers|thank you)\\b', '^\\s*[-~]+\\s*$']) %}
      - {{ pattern }}
      {%- endfor %}
    email_pattern: '{{ utils.anonymizer.email_pattern | default("[\\w\\.-]+@[\\w\\.-]+\\.\\w+") }}'
    # This is a JIRA specific username pattern
    username_pattern: '{{ utils.anonymizer.username_pattern | default("\\[~[^\\]]+\\]") }}'
  {%- endif %}

verbosity: {{ verbosity | default(3, true) }}
